{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This example code assumes you have already constructed\n",
    "#your full database of covariates, including anything (i.e., Clinics) you have\n",
    "#downloaded from google maps.\n",
    "#Further, it relies on conflict events in Liberia (as opposed to your assignment)\n",
    "#which asks for Syria.\n",
    "\n",
    "#The purpose of this assignment is to use simulation to establish what model\n",
    "#best estimates conflict under conditions of uncertainty, in both\n",
    "#your ancillary data (the data you use to predict) as well as\n",
    "#your conflict outcome varaible (the variable you are predicting).\n",
    "\n",
    "#Library imports:\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, I am loading my completed CSV in.\n",
    "full_dta = pd.read_csv(\"/sciclone/home2/geogdan/Project_3/model_dta.csv\", delimiter=\",\")\n",
    "print(len(full_dta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have many columns of data I want to keep this time, but there are a few not relevant for this analysis.\n",
    "#Columns before we drop:\n",
    "print(full_dta.columns.values )\n",
    "\n",
    "remove_columns_dta = full_dta.drop('NL_NAME_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_0', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_1', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ISO', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_2', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('CCA_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('CCN_3', axis=1)\n",
    "\n",
    "#I accidently requested v4composites_calibrated two times, so received duplicate data\n",
    "#in my CSV file.  Here, I'm removing columns based on a text\n",
    "#match (all duplicates end in \".1\")\n",
    "remove_columns_dta = remove_columns_dta[remove_columns_dta.columns.drop(list(remove_columns_dta.filter(regex='\\.1')))]\n",
    "\n",
    "remove_columns_dta = remove_columns_dta.drop('asdf_id', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_2', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_0', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_1', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('VARNAME_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('TYPE_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ENGTYPE_3', axis=1)\n",
    "\n",
    "#Save this as a shorter name for convenience\n",
    "fin_dta = remove_columns_dta\n",
    "\n",
    "#Columns after we drop:\n",
    "print(\"=========================== AFTER DROPPING ==========================\")\n",
    "print(remove_columns_dta.columns.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a description of my data.\n",
    "#Make sure the variable you're trying to predict\n",
    "#has meaningful information!\n",
    "pd.set_option('display.max_columns',500)\n",
    "remove_columns_dta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ultimately, I seek to predict 'acled_v3_count.none.sum'.\n",
    "#By reading the metadata provided with this variable, I know this\n",
    "#value is a sum of conflict events, where larger values.\n",
    "#indicate more conflict.\n",
    "\n",
    "#First, we're going to calculate a (very simple) linear model,\n",
    "#and assess how good it's fit is.  We're going to use\n",
    "#SciKit Learn for this, as all of the models we will test\n",
    "#are within that module for most of the rest of this course.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#We have to manipulate our Pandas dataframe in a few ways to\n",
    "#ensure it's compatible with SciKit\n",
    "columns = fin_dta.columns.tolist()\n",
    "\n",
    "#Establish the variable we will be predicting\n",
    "prediction_var = \"acled_v3_count.none.sum\"\n",
    "print(\"Predicting the variable: \" + prediction_var)\n",
    "\n",
    "#Make a list of all the datasets we're predicitng with\n",
    "#We need to remove the dataset we're predicting.\n",
    "data_to_predict_with = fin_dta.drop(prediction_var,1).columns.tolist()\n",
    "print(\"Predicting with the data:\")\n",
    "print(data_to_predict_with)\n",
    "\n",
    "# Generate a dataset to calibrate our model with\n",
    "# We will test our model against the remaining data.\n",
    "\n",
    "calibrate_data = fin_dta.sample(frac=0.8)\n",
    "testing_data = fin_dta.loc[~fin_dta.index.isin(calibrate_data.index)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check - how big is our training and test data?\n",
    "from sklearn import linear_model\n",
    "print(len(calibrate_data))\n",
    "print(len(testing_data))\n",
    "\n",
    "#Convert our pandas dataframe over to Numpy, \n",
    "#which is required for SciKit (the tool we're using for models)\n",
    "data_to_predict_with_np = calibrate_data[data_to_predict_with].values\n",
    "prediction_var_np = calibrate_data[prediction_var].values\n",
    "\n",
    "#Same for our test data:\n",
    "data_to_predict_tests = testing_data[data_to_predict_with].values\n",
    "prediction_var_test_np = testing_data[prediction_var].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fit a linear model as in project 2\n",
    "#but this time, using SciKit Learn\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Fit the model with our *calibration* dataset:\n",
    "regression_model = linear_model.LinearRegression()\n",
    "regression_model.fit(X=data_to_predict_with_np,y=prediction_var_np)\n",
    "\n",
    "#Predict the results for our *test* dataset:\n",
    "prediction_reg = regression_model.predict(data_to_predict_tests)\n",
    "\n",
    "#This calculates a linear weighted combination estimate of conflict based on our\n",
    "#model coefficients.\n",
    "#These coefficients are listed in the same order as\n",
    "#print(data_to_predict_with)\n",
    "print(regression_model.coef_)\n",
    "\n",
    "print(\"=====Predicted Mean Conflict Events for Test Dataset=======\")\n",
    "print(prediction_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at how well our linear model did\n",
    "#Note this can be different dependign on your cross-validation dataset\n",
    "#When we only do it once.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "print(mean_absolute_error(y_true=prediction_var_test_np, y_pred=prediction_reg))\n",
    "print(median_absolute_error(y_true=prediction_var_test_np, y_pred=prediction_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fit a Bayes model as our second\n",
    "#model to compare.\n",
    "#You can learn more about Bayes Ridge Regression - and many more SciKit models -\n",
    "# at http://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "#Here we need to define prior\n",
    "#assumptions.  In this case, we are defining the shape of a gamma distribution\n",
    "#through the terms alpha 1 and lambda 1.\n",
    "#This is used as the \"prior assumption\" for bayes (i.e.,\n",
    "#in the coin flip example, we assume a 50/50 split.  This gaussian distribution\n",
    "#describes our prior belief as to the likely values of our parameters).\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "BRR_model = linear_model.BayesianRidge(alpha_1 = 10, lambda_1=5)\n",
    "BRR_model.fit(X=data_to_predict_with_np,y=prediction_var_np)\n",
    "prediction_BRR = BRR_model.predict(data_to_predict_tests)\n",
    "\n",
    "#How did it do?\n",
    "print(mean_absolute_error(y_true=prediction_var_test_np, y_pred=prediction_BRR))\n",
    "print(median_absolute_error(y_true=prediction_var_test_np, y_pred=prediction_BRR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we want to setup a loop that looks across all of our models to see which one performs best.\n",
    "#We'll start simple, just doing a linear model.\n",
    "#Because we're iterating, we'll be changing our cross-validation subset each time.\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "#We'll time the runs for later steps...\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "iterations = 1000\n",
    "count = 0\n",
    "linear_reg_MAE = []\n",
    "linear_reg_model = []\n",
    "linear_reg_r2 = []\n",
    "\n",
    "while count < iterations:\n",
    "    \n",
    "    #Build four datasets each iteration - \n",
    "    #(D-1) A calibration dataset of covariates\n",
    "    #(D-2) A calibration dataset of outcomes\n",
    "    #(D-3) A validation dataset of covariates\n",
    "    #(D-4) A validation dataset of outcomes\n",
    "    #We'll also go ahead and convert everything over to numpy.\n",
    "    \n",
    "    #Building D1 and D2:\n",
    "    #Take 60% of our data and put it into calibration.\n",
    "    calibrate_data = fin_dta.sample(frac=0.60)\n",
    "    #D-1\n",
    "    calibrate_covariates = calibrate_data[data_to_predict_with].values\n",
    "    #D-2\n",
    "    calibrate_outcomes = calibrate_data[prediction_var].values\n",
    "    \n",
    "    \n",
    "    #Building D3 and D4:\n",
    "    #Take the other 40% of our data and use it for testing.\n",
    "    test_data = fin_dta.loc[~fin_dta.index.isin(calibrate_data.index)]\n",
    "\n",
    "    #D-3\n",
    "    test_covariates = test_data[data_to_predict_with].values\n",
    "    #D-4\n",
    "    test_outcomes = test_data[prediction_var].values\n",
    "    \n",
    "    #==================================================\n",
    "    #Build linear models with this calibration and test data\n",
    "    regression_model = linear_model.LinearRegression()\n",
    "    regression_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "    prediction_reg = regression_model.predict(test_covariates)\n",
    "    \n",
    "    linear_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_reg))\n",
    "    linear_reg_model.append(regression_model)\n",
    "    linear_reg_r2.append(r2_score(y_true=test_outcomes, y_pred=prediction_reg))\n",
    "    \n",
    "    count = count + 1\n",
    "\n",
    "\n",
    "#Iteration ID of best model:\n",
    "best_id = linear_reg_MAE.index(min(linear_reg_MAE))\n",
    "best_MAE = linear_reg_MAE[best_id]\n",
    "best_r2 = linear_reg_r2[best_id]\n",
    "\n",
    "#Best overall model based on MAE\n",
    "print(\"Best Model ID and MAE:\")\n",
    "print(best_id)\n",
    "print(best_MAE)\n",
    "\n",
    "#Distribution of all R2 from all models (this is analgolous to what you did in project 2)\n",
    "#Note: R2 can go below -1 in this case, as we're validating against\n",
    "#a dataset other than that which we used to fit our data.\n",
    "#This can happen when your model is *even worse* than simply assuming\n",
    "#the mean value ine very case.\n",
    "#sns.distplot(linear_reg_r2)\n",
    "\n",
    "#Let's look at the distribution of MAE\n",
    "sns.distplot(linear_reg_MAE, norm_hist=False, kde=False)\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "print(\"Runtime in seconds:\")\n",
    "print(stop_time - start_time)\n",
    "\n",
    "#Question to think about:\n",
    "#Based on the results from this section, what is the best and worst accuracy achieved by this model?\n",
    "#In terms of the observed data, is that accuracy acceptable?\n",
    "#Would you advocate for the use of this model in a real-world scenario?  Why or why not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's complicate our above code by adding the Bayes approach in:\n",
    "from random import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "#We'll time the runs for later steps...\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "iterations = 100\n",
    "count = 0\n",
    "linear_reg_MAE = []\n",
    "linear_reg_model = []\n",
    "\n",
    "bayes_reg_MAE = []\n",
    "bayes_reg_model = []\n",
    "\n",
    "while count < iterations:\n",
    "    \n",
    "    #Build four datasets each iteration - \n",
    "    #(D-1) A calibration dataset of covariates\n",
    "    #(D-2) A calibration dataset of outcomes\n",
    "    #(D-3) A validation dataset of covariates\n",
    "    #(D-4) A validation dataset of outcomes\n",
    "    #We'll also go ahead and convert everything over to numpy.\n",
    "    \n",
    "    #Building D1 and D2:\n",
    "    #Take 60% of our data and put it into calibration.\n",
    "    calibrate_data = fin_dta.sample(frac=0.60)\n",
    "    #D-1\n",
    "    calibrate_covariates = calibrate_data[data_to_predict_with].values\n",
    "    #D-2\n",
    "    calibrate_outcomes = calibrate_data[prediction_var].values\n",
    "    \n",
    "    \n",
    "    #Building D3 and D4:\n",
    "    #Take the other 40% of our data and use it for testing.\n",
    "    test_data = fin_dta.loc[~fin_dta.index.isin(calibrate_data.index)]\n",
    "\n",
    "    #D-3\n",
    "    test_covariates = test_data[data_to_predict_with].values\n",
    "    #D-4\n",
    "    test_outcomes = test_data[prediction_var].values\n",
    "    \n",
    "    #==================================================\n",
    "    #Build linear models with this calibration and test data\n",
    "    regression_model = linear_model.LinearRegression()\n",
    "    regression_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "    prediction_reg = regression_model.predict(test_covariates)\n",
    "    \n",
    "    linear_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_reg))\n",
    "    linear_reg_model.append(regression_model)\n",
    "\n",
    "    \n",
    "    \n",
    "      \n",
    "    #==================================================\n",
    "    #Bayes Modeling\n",
    "    #Here, we're going to loop again, because we want to test across\n",
    "    #a number of different alpha_1 and lambda_1 values.\n",
    "    bayes_iterations = iterations\n",
    "    bayes_counter = 0\n",
    "    while bayes_counter < bayes_iterations:\n",
    "        a = random()\n",
    "        l = random()\n",
    "        BRR_model = linear_model.BayesianRidge(alpha_1 = a, lambda_1=l)\n",
    "        BRR_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "        prediction_BRR = BRR_model.predict(test_covariates)\n",
    "\n",
    "        #Save the results.  We'll have more Bayes models due to the alpha and lambda search.\n",
    "        bayes_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_BRR))\n",
    "        bayes_reg_model.append(BRR_model)\n",
    "        bayes_counter = bayes_counter + 1\n",
    "        \n",
    "\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "#Iteration ID of best model for regression:\n",
    "best_id_lr = linear_reg_MAE.index(min(linear_reg_MAE))\n",
    "best_MAE_lr = linear_reg_MAE[best_id_lr]\n",
    "\n",
    "\n",
    "#Best overall model based on MAE\n",
    "print(\"Best Model ID and MAE for Linear Regression:\")\n",
    "print(best_id_lr)\n",
    "print(best_MAE_lr)\n",
    "\n",
    "\n",
    "#Iteration ID of best model for Bayes Ridge Regression:\n",
    "best_id_bayes = bayes_reg_MAE.index(min(bayes_reg_MAE))\n",
    "best_MAE_bayes = bayes_reg_MAE[best_id_bayes]\n",
    "\n",
    "print(\"Best Model ID and MAE for Bayes:\")\n",
    "print(best_id_bayes)\n",
    "print(best_MAE_bayes)\n",
    "\n",
    "#Distributions:\n",
    "sns.distplot(linear_reg_MAE, norm_hist=False, kde=False, label=\"Linear Regression\")\n",
    "sns.distplot(bayes_reg_MAE, norm_hist=False, kde=False, label=\"Bayes Ridge Reg\")\n",
    "plt.legend()\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "print(\"Runtime in seconds:\")\n",
    "print(stop_time - start_time)\n",
    "\n",
    "#Questions to consider:\n",
    "#Which of these two models would you use so far?\n",
    "#How much error could you expect if you used them?\n",
    "#How might you improve the estimation of the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we need to add uncertainty in.\n",
    "#This follows the same approach as project 2,\n",
    "#except we will automatically assign uncertainty \n",
    "#to all of our variables according to a generalized assumption\n",
    "#of gaussian uncertainty and a level of confidence\n",
    "#we want to achieve.\n",
    "\n",
    "from random import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "#We'll time the runs for later steps...\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "iterations = 10\n",
    "count = 0\n",
    "\n",
    "#Level of potential error in our data, following a\n",
    "#normal distribution for every variable.\n",
    "uncertainty_range = .10\n",
    "\n",
    "linear_reg_MAE = []\n",
    "linear_reg_model = []\n",
    "\n",
    "bayes_reg_MAE = []\n",
    "bayes_reg_model = []\n",
    "\n",
    "while count < iterations:\n",
    "\n",
    "    #Generate our new dataset that we will introduce uncertainty into.\n",
    "    sim_dta = fin_dta.applymap(lambda x: x +(np.random.normal(0, uncertainty_range/1.645, 1) * x))\n",
    "\n",
    "    calibrate_data = sim_dta.sample(frac=0.60)\n",
    "    calibrate_covariates = calibrate_data[data_to_predict_with].values\n",
    "    calibrate_outcomes = calibrate_data[prediction_var].values\n",
    "    \n",
    "    #Building D3 and D4:\n",
    "    #Take the other 40% of our data and use it for testing.\n",
    "    test_data = sim_dta.loc[~sim_dta.index.isin(calibrate_data.index)]\n",
    "\n",
    "    #D-3\n",
    "    test_covariates = test_data[data_to_predict_with].values\n",
    "    #D-4\n",
    "    test_outcomes = test_data[prediction_var].values\n",
    "    \n",
    "    #==================================================\n",
    "    #Build linear models with this calibration and test data\n",
    "    regression_model = linear_model.LinearRegression()\n",
    "    regression_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "    prediction_reg = regression_model.predict(test_covariates)\n",
    "    \n",
    "    linear_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_reg))\n",
    "    linear_reg_model.append(regression_model)\n",
    "\n",
    "    \n",
    "    \n",
    "      \n",
    "    #==================================================\n",
    "    #Bayes Modeling\n",
    "    #Here, we're going to loop again, because we want to test across\n",
    "    #a number of different alpha_1 and lambda_1 values.\n",
    "    bayes_iterations = iterations\n",
    "    bayes_counter = 0\n",
    "    while bayes_counter < bayes_iterations:\n",
    "        a = random()\n",
    "        l = random()\n",
    "        BRR_model = linear_model.BayesianRidge(alpha_1 = a, lambda_1=l)\n",
    "        BRR_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "        prediction_BRR = BRR_model.predict(test_covariates)\n",
    "\n",
    "        #Save the results.  We'll have more Bayes models due to the alpha and lambda search.\n",
    "        bayes_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_BRR))\n",
    "        bayes_reg_model.append(BRR_model)\n",
    "        bayes_counter = bayes_counter + 1\n",
    "        \n",
    "\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "#Iteration ID of best model for regression:\n",
    "best_id_lr = linear_reg_MAE.index(min(linear_reg_MAE))\n",
    "best_MAE_lr = linear_reg_MAE[best_id_lr]\n",
    "\n",
    "\n",
    "#Best overall model based on MAE\n",
    "print(\"Best Model ID and MAE for Linear Regression:\")\n",
    "print(best_id_lr)\n",
    "print(best_MAE_lr)\n",
    "\n",
    "\n",
    "#Iteration ID of best model for Bayes Ridge Regression:\n",
    "best_id_bayes = bayes_reg_MAE.index(min(bayes_reg_MAE))\n",
    "best_MAE_bayes = bayes_reg_MAE[best_id_bayes]\n",
    "print(\"==========================\")\n",
    "print(\"Best Model ID and MAE for Bayes:\")\n",
    "print(best_id_bayes)\n",
    "print(best_MAE_bayes)\n",
    "\n",
    "#Distributions:\n",
    "sns.distplot(linear_reg_MAE, norm_hist=False, kde=False, label=\"Linear Regression\")\n",
    "sns.distplot(bayes_reg_MAE, norm_hist=False, kde=False, label=\"Bayes Ridge Reg\")\n",
    "plt.legend()\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "print(\"==========================\")\n",
    "print(\"Runtime in seconds:\")\n",
    "print(stop_time - start_time)\n",
    "\n",
    "#Consider two questions:\n",
    "#(1) How can I add more (or less) uncertainty into certain variables?\n",
    "#(2) How has the distribution generated with uncertainty changed as contrasted\n",
    "#to the distribution generated without uncertainty?\n",
    "\n",
    "#Stats:\n",
    "#10 Models - 1.28 seconds\n",
    "#100 Models - 36.52 seconds\n",
    "#1000 Models - 520.23 seconds (~9 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Cluster\n",
      "<Client: scheduler='tcp://127.0.0.1:44556' processes=64 cores=64>\n",
      "Job submission initialized.  Cluster tasks being generated.\n",
      "[<Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-0>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-1>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-2>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-3>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-4>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-5>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-6>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-7>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-8>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-9>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-10>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-11>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-12>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-13>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-14>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-15>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-16>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-17>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-18>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-19>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-20>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-21>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-22>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-23>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-24>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-25>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-26>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-27>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-28>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-29>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-30>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-31>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-32>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-33>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-34>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-35>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-36>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-37>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-38>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-39>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-40>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-41>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-42>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-43>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-44>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-45>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-46>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-47>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-48>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-49>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-50>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-51>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-52>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-53>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-54>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-55>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-56>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-57>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-58>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-59>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-60>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-61>, <Future: status: pending, key: scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-62>]\n",
      "{'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-36': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-52': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-17': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-37': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-24': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-12': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-50': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-16': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-27': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-22': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-32': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-43': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-3': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-21': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-55': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-41': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-51': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-46': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-54': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-18': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-39': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-31': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-58': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-26': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-44': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-10': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-5': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-15': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-0': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-29': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-42': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-34': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-25': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-4': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-7': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-49': ['tcp://127.0.0.1:38699'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-47': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-13': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-6': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-20': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-2': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-40': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-23': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-11': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-35': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-8': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-1': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-56': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-38': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-45': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-14': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-19': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-53': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-9': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-28': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-59': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-33': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-61': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-48': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-60': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-57': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-30': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-62': []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-36': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-52': ['tcp://127.0.0.1:36290'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-17': ['tcp://127.0.0.1:33443'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-37': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-24': ['tcp://127.0.0.1:40689'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-12': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-50': ['tcp://127.0.0.1:37675'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-16': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-27': ['tcp://127.0.0.1:36207'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-22': ['tcp://127.0.0.1:42900'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-32': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-43': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-3': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-21': ['tcp://127.0.0.1:44467'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-55': ['tcp://127.0.0.1:35025'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-41': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-51': ['tcp://127.0.0.1:36904'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-46': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-54': ['tcp://127.0.0.1:35499'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-18': ['tcp://127.0.0.1:36013'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-39': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-31': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-58': ['tcp://127.0.0.1:34418'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-26': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-44': ['tcp://127.0.0.1:40424'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-10': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-5': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-15': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-0': ['tcp://127.0.0.1:45679'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-29': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-42': ['tcp://127.0.0.1:41337'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-34': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-25': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-4': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-7': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-49': ['tcp://127.0.0.1:38699'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-47': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-13': ['tcp://127.0.0.1:36554'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-6': ['tcp://127.0.0.1:41567'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-20': ['tcp://127.0.0.1:46121'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-2': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-40': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-23': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-11': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-35': ['tcp://127.0.0.1:44215'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-8': ['tcp://127.0.0.1:40367'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-1': ['tcp://127.0.0.1:45270'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-56': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-38': ['tcp://127.0.0.1:42393'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-45': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-14': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-19': ['tcp://127.0.0.1:34129'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-53': ['tcp://127.0.0.1:36139'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-9': ['tcp://127.0.0.1:40182'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-28': ['tcp://127.0.0.1:34961'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-59': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-33': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-61': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-48': ['tcp://127.0.0.1:38962'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-60': ['tcp://127.0.0.1:33573'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-57': ['tcp://127.0.0.1:34598'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-30': [], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-62': []}\n",
      "{'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-36': ['tcp://127.0.0.1:43584'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-52': ['tcp://127.0.0.1:36290'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-17': ['tcp://127.0.0.1:33443'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-37': ['tcp://127.0.0.1:43247'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-24': ['tcp://127.0.0.1:40689'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-12': ['tcp://127.0.0.1:37345'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-50': ['tcp://127.0.0.1:37675'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-16': ['tcp://127.0.0.1:34545'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-27': ['tcp://127.0.0.1:36207'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-22': ['tcp://127.0.0.1:42900'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-32': ['tcp://127.0.0.1:46107'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-43': ['tcp://127.0.0.1:40709'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-3': ['tcp://127.0.0.1:43531'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-21': ['tcp://127.0.0.1:44467'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-55': ['tcp://127.0.0.1:35025'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-41': ['tcp://127.0.0.1:41807'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-51': ['tcp://127.0.0.1:36904'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-46': ['tcp://127.0.0.1:39859'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-54': ['tcp://127.0.0.1:35499'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-18': ['tcp://127.0.0.1:36013'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-39': ['tcp://127.0.0.1:42333'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-31': ['tcp://127.0.0.1:46156'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-58': ['tcp://127.0.0.1:34418'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-26': ['tcp://127.0.0.1:38329'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-44': ['tcp://127.0.0.1:40424'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-10': ['tcp://127.0.0.1:39026'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-5': ['tcp://127.0.0.1:42087'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-15': ['tcp://127.0.0.1:34789'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-0': ['tcp://127.0.0.1:45679'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-29': ['tcp://127.0.0.1:34194'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-42': ['tcp://127.0.0.1:41337'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-34': ['tcp://127.0.0.1:44825'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-25': ['tcp://127.0.0.1:39191'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-4': ['tcp://127.0.0.1:42371'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-7': ['tcp://127.0.0.1:40794'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-49': ['tcp://127.0.0.1:38699'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-47': ['tcp://127.0.0.1:39141'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-13': ['tcp://127.0.0.1:36554'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-6': ['tcp://127.0.0.1:41567'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-20': ['tcp://127.0.0.1:46121'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-2': ['tcp://127.0.0.1:43772'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-40': ['tcp://127.0.0.1:42029'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-23': ['tcp://127.0.0.1:41876'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-11': ['tcp://127.0.0.1:38920'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-35': ['tcp://127.0.0.1:44215'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-8': ['tcp://127.0.0.1:40367'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-1': ['tcp://127.0.0.1:45270'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-56': ['tcp://127.0.0.1:34863'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-38': ['tcp://127.0.0.1:42393'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-45': ['tcp://127.0.0.1:40340'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-14': ['tcp://127.0.0.1:35242'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-19': ['tcp://127.0.0.1:34129'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-53': ['tcp://127.0.0.1:36139'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-9': ['tcp://127.0.0.1:40182'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-28': ['tcp://127.0.0.1:34961'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-59': ['tcp://127.0.0.1:34166'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-33': ['tcp://127.0.0.1:45468'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-61': ['tcp://127.0.0.1:33258'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-48': ['tcp://127.0.0.1:38962'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-60': ['tcp://127.0.0.1:33573'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-57': ['tcp://127.0.0.1:34598'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-30': ['tcp://127.0.0.1:33209'], 'scikit_rand-1c4b3ddc-1d78-4881-a9eb-60afffde6dd4-62': ['tcp://127.0.0.1:32897']}\n",
      "Runtime in seconds:\n",
      "52.279628046322614\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFKCAYAAADITfxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhGAGAMAgBDMAAAYhmAEAMAjBDACAQf4/iJVjlJSb/5kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b49bd0c7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading Modules\")\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from random import *\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "from time import sleep\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from operator import add\n",
    "from itertools import chain\n",
    "\n",
    "full_dta = pd.read_csv(\"/sciclone/home2/geogdan/Project_3/model_dta.csv\", delimiter=\",\")\n",
    "remove_columns_dta = full_dta.drop('NL_NAME_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_0', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_1', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ISO', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ID_2', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('CCA_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('CCN_3', axis=1)\n",
    "\n",
    "#I accidently requested v4composites_calibrated two times, so received duplicate data\n",
    "#in my CSV file.  Here, I'm removing columns based on a text\n",
    "#match (all duplicates end in \".1\")\n",
    "remove_columns_dta = remove_columns_dta[remove_columns_dta.columns.drop(list(remove_columns_dta.filter(regex='\\.1')))]\n",
    "\n",
    "remove_columns_dta = remove_columns_dta.drop('asdf_id', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_2', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_0', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('NAME_1', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('VARNAME_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('TYPE_3', axis=1)\n",
    "remove_columns_dta = remove_columns_dta.drop('ENGTYPE_3', axis=1)\n",
    "\n",
    "#Save this as a shorter name for convenience\n",
    "fin_dta = remove_columns_dta\n",
    "\n",
    "#We have to manipulate our Pandas dataframe in a few ways to\n",
    "#ensure it's compatible with SciKit\n",
    "columns = fin_dta.columns.tolist()\n",
    "\n",
    "#Establish the variable names\n",
    "prediction_var = \"acled_v3_count.none.sum\"\n",
    "data_to_predict_with = fin_dta.drop(prediction_var,1).columns.tolist()\n",
    "\n",
    "#We'll time the runs for later steps...\n",
    "#As the above illustrates, adding uncertainty into these simulations\n",
    "#can add quite a lot of time to the calculations.\n",
    "#Every iteration is currently taking around 0.15 seconds (check this on your own! Your data may take longer).\n",
    "#In this example, we are permuting (a) 30 variables by adding uncertainty and (b) two parameters (alpha and lambda for bayes)\n",
    "#If we want at least 100 samples to describe any single distribution, to capture all of these interacting parameters we \n",
    "#want 100 ^ 32 or 1e^64 simulations.  This would take approximately the time a newborn sun takes to burn out.\n",
    "#Recognizing we can't possibly capture *every* possibility, instead we will randomly sample as many as we can reasonably do with\n",
    "#Sciclone and the resources allocated to you on Jupyter.\n",
    "#We are limited to 64 processes on 32 cores for 6 hours.\n",
    "\n",
    "#First, we initalize our distributed cores - note this will take a few minutes each time:\n",
    "from dask.distributed import Client\n",
    "\n",
    "print(\"Launching Cluster\")\n",
    "client = Client()  # set up local cluster on your laptop\n",
    "print(client)\n",
    "\n",
    "#Start a timer for comparison\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "#Second, we need to take the code we wrote in the previous snippet and \n",
    "#turn it into a function we can send off to each client to\n",
    "#work on:\n",
    "\n",
    "def scikit_rand(iterations = 5):\n",
    "    count = 0\n",
    "\n",
    "    #Level of potential error in our data, following a\n",
    "    #normal distribution for every variable.\n",
    "    uncertainty_range = .10\n",
    "\n",
    "    linear_reg_MAE = []\n",
    "    linear_reg_model = []\n",
    "\n",
    "    bayes_reg_MAE = []\n",
    "    bayes_reg_model = []\n",
    "\n",
    "    while count < iterations:\n",
    "\n",
    "        sim_dta = fin_dta.applymap(lambda x: x +(np.random.normal(0, uncertainty_range/1.645, 1) * x))\n",
    "        calibrate_data = sim_dta.sample(frac=0.60)\n",
    "        calibrate_covariates = calibrate_data[data_to_predict_with].values\n",
    "        calibrate_outcomes = calibrate_data[prediction_var].values\n",
    "\n",
    "        test_data = sim_dta.loc[~sim_dta.index.isin(calibrate_data.index)]\n",
    "        test_covariates = test_data[data_to_predict_with].values\n",
    "        test_outcomes = test_data[prediction_var].values\n",
    "\n",
    "        #==================================================\n",
    "        #Build linear models with this calibration and test data\n",
    "        regression_model = linear_model.LinearRegression()\n",
    "        regression_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "        prediction_reg = regression_model.predict(test_covariates)\n",
    "\n",
    "        linear_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_reg))\n",
    "        linear_reg_model.append(regression_model)\n",
    "\n",
    "        #==================================================\n",
    "        #Bayes Modeling\n",
    "        bayes_iterations = iterations\n",
    "        bayes_counter = 0\n",
    "        while bayes_counter < bayes_iterations:\n",
    "            a = random()\n",
    "            l = random()\n",
    "            BRR_model = linear_model.BayesianRidge(alpha_1 = a, lambda_1=l)\n",
    "            BRR_model.fit(X=calibrate_covariates,y=calibrate_outcomes)\n",
    "            prediction_BRR = BRR_model.predict(test_covariates)\n",
    "\n",
    "            #Save the results.  We'll have more Bayes models due to the alpha and lambda search.\n",
    "            bayes_reg_MAE.append(mean_absolute_error(y_true=test_outcomes, y_pred=prediction_BRR))\n",
    "            bayes_reg_model.append(BRR_model)\n",
    "            bayes_counter = bayes_counter + 1\n",
    "\n",
    "        count = count + 1\n",
    "    return(linear_reg_MAE,linear_reg_model,bayes_reg_MAE,bayes_reg_model)\n",
    "\n",
    "#Now, we can call clients and distribute the functions as we want:\n",
    "core_iterations = [None] * 63 # 63 cores (2 threads / core) (we save one for Jupyter just in case)\n",
    "for i in range(63):\n",
    "    core_iterations[i] = 5 #Every node will do 5 iterations.\n",
    "\n",
    "job_submission = client.map(scikit_rand,core_iterations, pure=False)\n",
    "print(\"Job submission initialized.  Cluster tasks being generated.\")\n",
    "print(job_submission)\n",
    "\n",
    "#A small while loop so we can keep track of what's going on:\n",
    "while(any(word in str(job_submission[0:62]) for word in ['pending'])):\n",
    "    sleep(10)\n",
    "    print(client.who_has(job_submission))\n",
    "      \n",
    "if(any(word in str(job_submission[0:62]) for word in ['error'])):\n",
    "    print(\"There was an error!\")\n",
    "else:\n",
    "    stop_time = timeit.default_timer()\n",
    "    print(\"Runtime in seconds:\")\n",
    "    print(stop_time - start_time)\n",
    "\n",
    "    lr_results = []\n",
    "    for i in range(63):\n",
    "        lr_results.append(client.gather(job_submission)[i][0])\n",
    "    lr_results =list(chain(*lr_results))\n",
    "    \n",
    "    \n",
    "        \n",
    "    brr_results = []\n",
    "    for i in range(63):\n",
    "        brr_results.append(client.gather(job_submission)[i][2])\n",
    "    brr_results =list(chain(*brr_results))\n",
    "    \n",
    "    sns.distplot(client.gather(lr_results), norm_hist=False, kde=False, label=\"Linear Regression\")\n",
    "    sns.distplot(client.gather(brr_results), norm_hist=False, kde=False, label=\"Bayes Ridge Reg\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Questions:\n",
    "#Which model performs best?\n",
    "#What is the minimum number of iterations you need to capture the true relationship?  How can you justify?\n",
    "#What's the absolute best you could do in terms of % error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
